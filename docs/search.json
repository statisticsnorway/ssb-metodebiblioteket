[
  {
    "objectID": "catalog.html",
    "href": "catalog.html",
    "title": "Katalog",
    "section": "",
    "text": "Her finner du en liste over alle funksjoner i Metodebiblioteket.\n\n\n\n\n// Read in data\ntestdata = JSON.parse(my_ojs_data)\n\n\n\n\n\n\n\nviewof lang = Inputs.checkbox([\"r\", \"python\"],\n  {label: \"Språk: \"}\n)\n\n\nviewof tema = Inputs.checkbox( [\"kontrollere\", \"imputere\", \"strukturere\", \"vektberegning\", \"indeksberegning\", \"usikkerhetsberegning\", \"sesongjustering\", \"konfidensialitet\", \"analyse\"],\n  {label: \"Metodeområde: \"}\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// Filter data based on check boxes\nfiltered = testdata.filter(function(data) {\n  \n  return lang.every(r=> data.keyword.includes(r)) &&\n    tema.every(r=> data.keyword.includes(r))\n    ;\n})\n\n\n\n\n\n\n\nfunction overflow_large(words) {\n  return (x) => htl.html`<div style=\"\n    display: inline-block;\n    width: 450px;\n    white-space: pre-line;\n    break-text: auto;\n    overflow-wrap: normal;\n    height: auto;\n    word-wrap: break-word;\n    overflow: auto;\n\">${x.toLocaleString(\"en\")}`;\n}\n\n// Function for formatting names\nfunction overflow_names(words) {\n  return (x) => htl.html`<div style=\"\n    display: inline-block;\n    width: 250px;\n    white-space: pre-line;\n    break-text: auto;\n    overflow-wrap: normal;\n    height: auto;\n    word-wrap: break-word;\n    overflow: auto;\n\">${x.toLocaleString(\"en\")}`;\n}\n\n// Function for adding hyperlinks\nfunction get_url(new_url) {\n  return (x) => htl.html`<a href=${x.split(\";\")[1]} target=_blank>${x.split(\";\")[0]} </a>`;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof filter_dt = Inputs.search(filtered)\n\ntable_out = Inputs.table(filter_dt, { columns: [\n    \"func_link\",\n    \"pack\",\n    \"navn\",\n    \"description\"\n  ],\n  header: {\n    func_link: \"Funksjon\",\n    pack: \"Pakke\",\n    navn: \"Navn\",\n    description: \"Beskrivelse\"\n  },\n  format: {\n  func_link: get_url(\n      filter_dt, \n      (d) => d[\"func_lnk\"]\n      ),\n  navn: overflow_names(\n  filter_dt,\n    (x) => x[\"navn\"]\n      ),\n  description: overflow_large(\n      filter_dt,\n      (x) => x[\"description\"]\n      ),\n  },\n  rows: 100\n})"
  },
  {
    "objectID": "catalogue_conf.html",
    "href": "catalogue_conf.html",
    "title": "Konfidensialitet",
    "section": "",
    "text": "Statistikkloven § 7. Statistisk konfidensialitet ved formidling av offisiell statistikk pålegger at vi ikke publiserer statistikk slik at statistisk informasjon kan føres tilbake til enkeltpersoner eller andre typer statistiske enheter. Hvis dette likevel skjer sier vi at det har funnet sted en avsløring.\nHvis hensynet til oppbyggingen av statistikken krever det, kan det i noen tilfeller gjøres unntak. Slik publisering må ikke være til skade for de statistiske enhetene som inngår i statistikken.\nAt vi i SSB følger dette er avgjørende for oppgavegivernes tillit til oss og for at vi skal kunne utføre vårt samfunnsoppdrag.\n\n\n\n\n// Read in data\ntestdata = JSON.parse(my_ojs_data)\n\n\n\n\n\n\n\nviewof tema = Inputs.checkbox( [\"undertrykking\", \"avrunding\", \"støylegging\"],\n  {label: \"Metodeområde: \"}\n)\n\n\n\n\n\n\n\n// Filter data based on check boxes\nfiltered = testdata.filter(function(data) {\n  \n  return tema.every(r=> data.keyword.includes(r))\n    ;\n})\n\n\n\n\n\n\n\nfunction overflow_large(words) {\n  return (x) => htl.html`<div style=\"\n    display: inline-block;\n    width: 450px;\n    white-space: pre-line;\n    break-text: auto;\n    overflow-wrap: normal;\n    height: auto;\n    word-wrap: break-word;\n    overflow: auto;\n\">${x.toLocaleString(\"en\")}`;\n}\n\n// Function for formatting names\nfunction overflow_names(words) {\n  return (x) => htl.html`<div style=\"\n    display: inline-block;\n    width: 250px;\n    white-space: pre-line;\n    break-text: auto;\n    overflow-wrap: normal;\n    height: auto;\n    word-wrap: break-word;\n    overflow: auto;\n\">${x.toLocaleString(\"en\")}`;\n}\n\n// Function for adding hyperlinks\nfunction get_url(new_url) {\n  return (x) => htl.html`<a href=${x.split(\";\")[1]} target=_blank>${x.split(\";\")[0]} </a>`;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof filter_dt = Inputs.search(filtered)\n\ntable_out = Inputs.table(filter_dt, { columns: [\n    \"func_link\",\n    \"pack\",\n    \"språk\",\n    \"navn\",\n    \"description\"\n  ],\n  header: {\n    func_link: \"Funksjon\",\n    pack: \"Pakke\",\n    språk: \"Språk\",\n    navn: \"Navn\",\n    description: \"Beskrivelse\"\n  },\n  format: {\n  func_link: get_url(\n      filter_dt, \n      (d) => d[\"func_lnk\"]\n      ),\n  navn: overflow_names(\n  filter_dt,\n    (x) => x[\"navn\"]\n      ),\n  description: overflow_large(\n      filter_dt,\n      (x) => x[\"description\"]\n      ),\n  },\n  rows: 100\n})"
  },
  {
    "objectID": "catalogue_edit.html",
    "href": "catalogue_edit.html",
    "title": "Dataeditiering",
    "section": "",
    "text": "Dataeditering er kontroll, granskning og retting av data. Det omfatter editering av populasjon, editering av åpenbare og systematiske feil, seleksjon av verdier med stort avvik og høy innflytelse og kontroll av aggregater som skal bli publisert. Metodene som blir brukt til dataeditering spenner fra logisk kontroll av gyldig verdiområde til maskinlæring. All statistikk som publiseres er basert på data som har blitt kontrollert og i de fleste tilfeller også korrigert.\nDu kan finne mer information om dataediteringsprosess på Byrånettet.\n\n\n\n\n// Read in data\ntestdata = JSON.parse(my_ojs_data)\n\n\n\n\n\n\n\nviewof tema = Inputs.checkbox( [\"kontrollere\", \"imputere\", \"donor\", \"modellbasert\"],\n  {label: \"Metodeområde: \"}\n)\n\n\n\n\n\n\n\n// Filter data based on check boxes\nfiltered = testdata.filter(function(data) {\n  \n  return tema.every(r=> data.keyword.includes(r))\n    ;\n})\n\n\n\n\n\n\n\nfunction overflow_large(words) {\n  return (x) => htl.html`<div style=\"\n    display: inline-block;\n    width: 450px;\n    white-space: pre-line;\n    break-text: auto;\n    overflow-wrap: normal;\n    height: auto;\n    word-wrap: break-word;\n    overflow: auto;\n\">${x.toLocaleString(\"en\")}`;\n}\n\n// Function for formatting names\nfunction overflow_names(words) {\n  return (x) => htl.html`<div style=\"\n    display: inline-block;\n    width: 250px;\n    white-space: pre-line;\n    break-text: auto;\n    overflow-wrap: normal;\n    height: auto;\n    word-wrap: break-word;\n    overflow: auto;\n\">${x.toLocaleString(\"en\")}`;\n}\n\n// Function for adding hyperlinks\nfunction get_url(new_url) {\n  return (x) => htl.html`<a href=${x.split(\";\")[1]} target=_blank>${x.split(\";\")[0]} </a>`;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof filter_dt = Inputs.search(filtered)\n\ntable_out = Inputs.table(filter_dt, { columns: [\n    \"func_link\",\n    \"pack\",\n    \"språk\",\n    \"navn\",\n    \"description\"\n  ],\n  header: {\n    func_link: \"Funksjon\",\n    pack: \"Pakke\",\n    språk: \"Språk\",\n    navn: \"Navn\",\n    description: \"Beskrivelse\"\n  },\n  format: {\n  func_link: get_url(\n      filter_dt, \n      (d) => d[\"func_lnk\"]\n      ),\n  navn: overflow_names(\n  filter_dt,\n    (x) => x[\"navn\"]\n      ),\n  description: overflow_large(\n      filter_dt,\n      (x) => x[\"description\"]\n      ),\n  },\n  rows: 100\n})"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Metodebiblioteket",
    "section": "",
    "text": "Metodebiblioteket er SSBs bibliotek for statistiske metode funksjoner. Metodene på liste er funksjoner skrevet i R eller python som passer i SSBs IT-platform. Alle funksjoner er testet av Seksjon for Metode for bruk i produksjon av offisielle statistikk. Alle er brukt i minst én produksjonsløp/eller brukt i SSBs interne metodekurs."
  },
  {
    "objectID": "prosess.html",
    "href": "prosess.html",
    "title": "Prosessmodell",
    "section": "",
    "text": "Når vi skal beskrive produksjonsprosessen for offisiell statistikk bruker vi FNs prosessmodell, Generic Statistical Business Process Model (GSBPM). Den beskriver og definerer prosessene som er nødvendige for å produsere offisiell statistikk.\nVi har samlet funksjoner i Metodebiblioteket etter prosessen de vanligvis benyttes i. Dette er kun ment som en hjelpemidle. Det er mulig at funksjonene kan benyttes i andre prosesser enn det som er beskrivet her.\n\n1 Avklare behov2 Planlegge3 Bygge4 Samle inn5 Klargjøre6 Analyse7 Formidle8 Evaluare\n\n\nIngen funksjoner enda.\n\n\nIngen funksjoner enda.\n\n\nIngen funksjoner enda.\n\n\nIngen funksjoner enda.\n\n\nVed klargjøring tenker vi mest ofte for dataediting men det inkludere også data integrering, klassifisering, beregning av vekter og aggregering. Her finner du funksjoner som kan benyttes i klargjørings steget\n\n5.1 Integrere Data5.2 Klassifisere og kode5.3 Kontrollere og validere5.4 Editere og imputere5.5 Avlede nye variabler5.6 Beregne vekter5.7 Beregne aggregater5.8 Ferdigstille datafiler\n\n\nIngen funksjoner enda.\n\n\nIngen funksjoner enda.\n\n\n\n\n\n\n \n  \n    Funksjon \n    Pakke \n    Navn \n    Språk \n    Beskrivelse \n  \n \n\n  \n    AggrSml2NumVar \n    Kostra \n    Aggregated comparison of two numerical variables \n    r \n    Calculating aggregated values for two numerical variables, useful for comparison of the variables \n  \n  \n    confront \n    validate \n    Confront data with a (set of) expressionset(s) \n    r \n    An expressionset is a general class storing rich expressions (basically expressions and some meta data) which we call 'rules'. Examples of expressionset implementations are 'validator' objects, storing validation rules and 'indicator' objects, storing data quality indicators. The 'confront' function evaluates the expressions one by one on a dataset while recording some process meta data. All results are stored in a (subclass of a) 'confrontation' object. \n  \n  \n    Diff2NumVar \n    Kostra \n    Difference between two numerical variables \n    r \n    Calculating the difference between two numerical variables Listing units with big difference, either the k units with the biggest absolute difference, or units with a absolute difference greater than a threshold Only units with value on both variables are used in the calculations \n  \n  \n    get_extremes \n    struktuR \n    Get extreme values Get extreme values in the sample dataset \n    r \n    Get extreme values Get extreme values in the sample dataset \n  \n  \n    Hb \n    Kostra \n    Detection of outliers using the Hidiroglou-Berthelot (HB) method \n    r \n    Detects possible outliers of a variable in period t by comparing it with revised values from period t-1 \n  \n  \n    LmImpute \n    Kostra \n    INTERNAL FUNCTION: Regeression imputation. \n    r \n    Imputation by weighted regeression, using lm, allowing multiple explanatory variables and multiple response variables. Impute missing and wrong values (category 3) by the model based on representative data (category 1). Some data are considered correct but not representative (category 2). \n  \n  \n    OutlierRegressionMicro \n    Kostra \n    Finding outliers of a sigle variable (y) by a regression model \n    r \n    outliers are found by using a limit for studentized residuals. \n  \n  \n    Quartile \n    Kostra \n    Detection of outliers using quartiles and by comparing with other \n    r \n    Detection of outliers using quartiles and by comparing with other data in same or previous period. \n  \n  \n    Rank2NumVar \n    Kostra \n    Comparing the biggest units with respect to two numerical \n    r \n    Calculating rank and share for two numerical variables, and the ratio between the variables Listing big units, either the k biggest units or units with value greater than a threshold \n  \n  \n    ThError \n    Kostra \n    Detection of 1000-error \n    r \n    Detects units with possible 1000-error by comparing values in period t with revised values from period t-1 \n  \n  \n    validator \n    validate \n    Define validation rules for data \n    r \n    Define validation rules for data \n  \n\n\n\n\n\n\n\n\n\n\n\n \n  \n    Funksjon \n    Pakke \n    Navn \n    Språk \n    Beskrivelse \n  \n \n\n  \n    impute_knn \n    simputation \n    Hot deck imputation \n    r \n    Hot-deck imputation methods include random and sequential hot deck, k-nearest neighbours imputation and predictive mean matching. \n  \n  \n    impute_pmm \n    simputation \n    Hot deck imputation \n    r \n    Hot-deck imputation methods include random and sequential hot deck, k-nearest neighbours imputation and predictive mean matching. \n  \n  \n    impute_proxy \n    simputation \n    Impute by variable derivation \n    r \n    Impute missing values by a constant, by copying another variable computing transformations from other variables. \n  \n  \n    impute_rhd \n    simputation \n    Hot deck imputation \n    r \n    Hot-deck imputation methods include random and sequential hot deck, k-nearest neighbours imputation and predictive mean matching. \n  \n  \n    lm \n    stats \n    Fitting Linear Models \n    r \n    'lm' is used to fit linear models, including multivariate ones. It can be used to carry out regression, single stratum analysis of variance and analysis of covariance (although 'aov' may provide a more convenient interface for these). \n  \n  \n    LmImpute \n    Kostra \n    INTERNAL FUNCTION: Regeression imputation. \n    r \n    Imputation by weighted regeression, using lm, allowing multiple explanatory variables and multiple response variables. Impute missing and wrong values (category 3) by the model based on representative data (category 1). Some data are considered correct but not representative (category 2). \n  \n\n\n\n\n\n\n\nIngen funksjoner enda\n\n\n\n\n\n\n \n  \n    Funksjon \n    Pakke \n    Navn \n    Språk \n    Beskrivelse \n  \n \n\n  \n    CalibrateSSB \n    CalibrateSSB \n    Calibration weighting and estimation \n    r \n    Compute weights by calibration and corresponding estimates, totals and residuals \n  \n  \n    PanelEstimation \n    CalibrateSSB \n    Variance estimation for panel data \n    r \n    Variance estimation of linear combinations of totals and ratios based on output from wideFromCalibrate \n  \n  \n    quantile_weighted \n    SSBtools \n    Weighted quantiles \n    r \n    The default method ('type=2') corresponds to weighted percentiles in SAS. \n  \n  \n    struktur_model \n    struktuR \n    Run a struktur model Estimates total and uncertainty for a rate, \n    r \n    Run a struktur model Estimates total and uncertainty for a rate, homogeneous or regression model within strata. \n  \n\n\n\n\n\n\n\nIngen funksjoner enda\n\n\nIngen funksjoner enda\n\n\n\n\n\n\n6.1 Utarbeid produktutkast6.2 Kvalitetssikre produkter6.3 Tolke og forklarer produkter6.4 Gjennomføre avslørings kontroll6.5 Ferdigstille produkter\n\n\nIngen funksjoner enda.\n\n\n\n\n\n\n \n  \n    Funksjon \n    Pakke \n    Navn \n    Språk \n    Beskrivelse \n  \n \n\n  \n    model_aggregate \n    SSBtools \n    Hierarchical aggregation via model specification \n    r \n    Internally a dummy/model matrix is created according to the model specification. This model matrix is used in the aggregation process via matrix multiplication and/or the function 'aggregate_multiple_fun'. \n  \n\n\n\n\n\n\n\nIngen funksjoner enda.\n\n\n\n\n\n\n \n  \n    Funksjon \n    Pakke \n    Navn \n    Språk \n    Beskrivelse \n  \n \n\n  \n    GaussSuppressDec \n    GaussSuppression \n    Cell suppression with synthetic decimal numbers \n    r \n    'GaussSuppressionFromData' is run and decimal numbers are added to output by a modified (for sparse matrix efficiency) version of 'SuppressDec'. \n  \n  \n    GaussSuppressionFromData \n    GaussSuppression \n    Cell suppression from input data containing inner cells \n    r \n    Aggregates are generated followed by primary suppression followed by secondary suppression by Gaussian elimination by 'GaussSuppression' \n  \n  \n    PLSroundingPublish \n    SmallCountRounding \n    PLS inspired rounding \n    r \n    Small count rounding of necessary inner cells are performed so that all small frequencies of cross-classifications to be published (publishable cells) are rounded. The publishable cells can be defined from a model formula, hierarchies or automatically from data. \n  \n  \n    ProtectKostra \n    Kostra \n    Table suppression according to a frequency rule following the \n    r \n    Table suppression according to a frequency rule following the standards in the Kostra project. \n  \n  \n    ProtectTableData \n    easySdcTable \n    Easy interface to sdcTable: Table suppression according to a \n    r \n    'GaussSuppression', 'protectTable' or 'protect_linked_tables' is run with a data set as the only required input. One (stacked) or several (unstacked) input variables can hold cell counts. 'ProtectTableData' is a tidy wrapper function, which returns a single data frame instead of a list ('info' omitted). \n  \n  \n    SdcForetakPerson \n    SdcForetakPerson \n    Prikking av foretak og avrunding eller prikking av personer \n    r \n    Prikking av foretak og avrunding eller prikking av personer. Sett parameteren 'allowTotal' til 'TRUE' for at kategorier innen ('within') foretak skal prikkes samtidig som totalverdier over disse grupperingene tillates publisert. \n  \n  \n    SuppressDominantCells \n    GaussSuppression \n    Suppress volume tables using dominant cell primary suppression. \n    r \n    Suppress volume tables using dominant cell primary suppression. \n  \n  \n    SuppressFewContributors \n    GaussSuppression \n    Few contributors suppression \n    r \n    This function provides functionality for suppressing volume tables based on the few contributors rule ('NContributorsRule'). \n  \n  \n    SuppressionFromDecimals \n    GaussSuppression \n    Cell suppression from synthetic decimal numbers \n    r \n    Decimal numbers, as calculated by 'GaussSuppressDec', are used to decide suppression (whole numbers or not). Technically, the calculations are done via 'GaussSuppressionFromData', but without running 'GaussSuppression'. All suppressed cells are primary suppressed. \n  \n  \n    SuppressKDisclosure \n    GaussSuppression \n    K-disclosure suppression \n    r \n    A function for suppressing frequency tables using the k-disclosure method. \n  \n  \n    SuppressSmallCounts \n    GaussSuppression \n    Small count frequency table suppression. \n    r \n    This is a wrapper function of 'GaussSuppressionFromData' for small count frequency suppression. For common applications, the 'spec' parameter can be adjusted, see 'PackageSpecs' for more information. See Details for more information on function call customization. \n  \n\n\n\n\n\n\n\nIngen funksjoner enda.\n\n\n\n\n\nIngen funksjoner enda\n\n\nIngen funksjoner enda"
  },
  {
    "objectID": "prosess.html#running-code",
    "href": "prosess.html#running-code",
    "title": "Prosessmodell",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "prosess.html#avklare-behov",
    "href": "prosess.html#avklare-behov",
    "title": "Prosessmodell",
    "section": "1 Avklare behov",
    "text": "1 Avklare behov\nIngen funksjoner enda."
  },
  {
    "objectID": "prosess.html#planlegge",
    "href": "prosess.html#planlegge",
    "title": "Prosessmodell",
    "section": "2 Planlegge",
    "text": "2 Planlegge\nIngen funksjoner enda."
  },
  {
    "objectID": "prosess.html#bygge",
    "href": "prosess.html#bygge",
    "title": "Prosessmodell",
    "section": "3 Bygge",
    "text": "3 Bygge\nIngen funksjoner enda."
  },
  {
    "objectID": "prosess.html#samle-inn",
    "href": "prosess.html#samle-inn",
    "title": "Prosessmodell",
    "section": "4 Samle inn",
    "text": "4 Samle inn\nIngen funksjoner enda."
  },
  {
    "objectID": "prosess.html#klargjøre",
    "href": "prosess.html#klargjøre",
    "title": "Prosessmodell",
    "section": "5 Klargjøre",
    "text": "5 Klargjøre\nVed klargjøring tenker vi mest ofte for dataediting men det inkludere også data integrering, klassifisering, beregning av vekter og aggregering. Her finner du funksjoner som kan benyttes i klargjørings steget\n\n\n5.1 Integrere Data\nIngen funksjoner enda.\n\n\n5.2 Klassifisere og kode\nIngen funksjoner enda.\n\n\n5.3 Kontrollere og validere\n\n\n\n\n \n  \n    Funksjon \n    Pakke \n    Navn \n    Språk \n    Beskrivelse \n  \n \n\n  \n    AggrSml2NumVar \n    Kostra \n    Aggregated comparison of two numerical variables \n    r \n    Calculating aggregated values for two numerical variables, useful for comparison of the variables \n  \n  \n    confront \n    validate \n    Confront data with a (set of) expressionset(s) \n    r \n    An expressionset is a general class storing rich expressions (basically expressions and some meta data) which we call 'rules'. Examples of expressionset implementations are 'validator' objects, storing validation rules and 'indicator' objects, storing data quality indicators. The 'confront' function evaluates the expressions one by one on a dataset while recording some process meta data. All results are stored in a (subclass of a) 'confrontation' object. \n  \n  \n    Diff2NumVar \n    Kostra \n    Difference between two numerical variables \n    r \n    Calculating the difference between two numerical variables Listing units with big difference, either the k units with the biggest absolute difference, or units with a absolute difference greater than a threshold Only units with value on both variables are used in the calculations \n  \n  \n    get_extremes \n    struktuR \n    Get extreme values Get extreme values in the sample dataset \n    r \n    Get extreme values Get extreme values in the sample dataset \n  \n  \n    Hb \n    Kostra \n    Detection of outliers using the Hidiroglou-Berthelot (HB) method \n    r \n    Detects possible outliers of a variable in period t by comparing it with revised values from period t-1 \n  \n  \n    LmImpute \n    Kostra \n    INTERNAL FUNCTION: Regeression imputation. \n    r \n    Imputation by weighted regeression, using lm, allowing multiple explanatory variables and multiple response variables. Impute missing and wrong values (category 3) by the model based on representative data (category 1). Some data are considered correct but not representative (category 2). \n  \n  \n    OutlierRegressionMicro \n    Kostra \n    Finding outliers of a sigle variable (y) by a regression model \n    r \n    outliers are found by using a limit for studentized residuals. \n  \n  \n    Quartile \n    Kostra \n    Detection of outliers using quartiles and by comparing with other \n    r \n    Detection of outliers using quartiles and by comparing with other data in same or previous period. \n  \n  \n    Rank2NumVar \n    Kostra \n    Comparing the biggest units with respect to two numerical \n    r \n    Calculating rank and share for two numerical variables, and the ratio between the variables Listing big units, either the k biggest units or units with value greater than a threshold \n  \n  \n    ThError \n    Kostra \n    Detection of 1000-error \n    r \n    Detects units with possible 1000-error by comparing values in period t with revised values from period t-1 \n  \n  \n    validator \n    validate \n    Define validation rules for data \n    r \n    Define validation rules for data \n  \n\n\n\n\n\n5.4 Editere og imputere\n\n\n\n\n \n  \n    Funksjon \n    Pakke \n    Navn \n    Språk \n    Beskrivelse \n  \n \n\n  \n    impute_knn \n    simputation \n    Hot deck imputation \n    r \n    Hot-deck imputation methods include random and sequential hot deck, k-nearest neighbours imputation and predictive mean matching. \n  \n  \n    impute_pmm \n    simputation \n    Hot deck imputation \n    r \n    Hot-deck imputation methods include random and sequential hot deck, k-nearest neighbours imputation and predictive mean matching. \n  \n  \n    impute_proxy \n    simputation \n    Impute by variable derivation \n    r \n    Impute missing values by a constant, by copying another variable computing transformations from other variables. \n  \n  \n    impute_rhd \n    simputation \n    Hot deck imputation \n    r \n    Hot-deck imputation methods include random and sequential hot deck, k-nearest neighbours imputation and predictive mean matching. \n  \n  \n    lm \n    stats \n    Fitting Linear Models \n    r \n    'lm' is used to fit linear models, including multivariate ones. It can be used to carry out regression, single stratum analysis of variance and analysis of covariance (although 'aov' may provide a more convenient interface for these). \n  \n  \n    LmImpute \n    Kostra \n    INTERNAL FUNCTION: Regeression imputation. \n    r \n    Imputation by weighted regeression, using lm, allowing multiple explanatory variables and multiple response variables. Impute missing and wrong values (category 3) by the model based on representative data (category 1). Some data are considered correct but not representative (category 2). \n  \n\n\n\n\n\n5.5 Avlede nye variabler\n5.6 Beregne vekter\n\n\n\n\n \n  \n    Funksjon \n    Pakke \n    Navn \n    Språk \n    Beskrivelse \n  \n \n\n  \n    CalibrateSSB \n    CalibrateSSB \n    Calibration weighting and estimation \n    r \n    Compute weights by calibration and corresponding estimates, totals and residuals \n  \n  \n    PanelEstimation \n    CalibrateSSB \n    Variance estimation for panel data \n    r \n    Variance estimation of linear combinations of totals and ratios based on output from wideFromCalibrate \n  \n  \n    quantile_weighted \n    SSBtools \n    Weighted quantiles \n    r \n    The default method ('type=2') corresponds to weighted percentiles in SAS. \n  \n  \n    struktur_model \n    struktuR \n    Run a struktur model Estimates total and uncertainty for a rate, \n    r \n    Run a struktur model Estimates total and uncertainty for a rate, homogeneous or regression model within strata. \n  \n\n\n\n\n\n5.7 Beregne aggregater\n5.8 Ferdigstille datafiler\n\n\n6 Analyse\n\n\n7 Formidle\n\n\n8 Evaluare"
  },
  {
    "objectID": "prosess.html#analyse",
    "href": "prosess.html#analyse",
    "title": "Prosessmodell",
    "section": "6 Analyse",
    "text": "6 Analyse"
  },
  {
    "objectID": "prosess.html#formidle",
    "href": "prosess.html#formidle",
    "title": "Prosessmodell",
    "section": "7 Formidle",
    "text": "7 Formidle"
  },
  {
    "objectID": "prosess.html#evaluare",
    "href": "prosess.html#evaluare",
    "title": "Prosessmodell",
    "section": "8 Evaluare",
    "text": "8 Evaluare"
  },
  {
    "objectID": "prosess.html#integrere-data",
    "href": "prosess.html#integrere-data",
    "title": "Prosessmodell",
    "section": "5.1 Integrere Data",
    "text": "5.1 Integrere Data\nIngen funksjoner enda."
  },
  {
    "objectID": "prosess.html#klassifisere-og-kode",
    "href": "prosess.html#klassifisere-og-kode",
    "title": "Prosessmodell",
    "section": "5.2 Klassifisere og kode",
    "text": "5.2 Klassifisere og kode\nIngen funksjoner enda.\n\n5.3 Kontrollere og validere\n\n\n\n\n \n  \n    Funksjon \n    Pakke \n    Navn \n    Språk \n    Beskrivelse \n  \n \n\n  \n    AggrSml2NumVar \n    Kostra \n    Aggregated comparison of two numerical variables \n    r \n    Calculating aggregated values for two numerical variables, useful for comparison of the variables \n  \n  \n    confront \n    validate \n    Confront data with a (set of) expressionset(s) \n    r \n    An expressionset is a general class storing rich expressions (basically expressions and some meta data) which we call 'rules'. Examples of expressionset implementations are 'validator' objects, storing validation rules and 'indicator' objects, storing data quality indicators. The 'confront' function evaluates the expressions one by one on a dataset while recording some process meta data. All results are stored in a (subclass of a) 'confrontation' object. \n  \n  \n    Diff2NumVar \n    Kostra \n    Difference between two numerical variables \n    r \n    Calculating the difference between two numerical variables Listing units with big difference, either the k units with the biggest absolute difference, or units with a absolute difference greater than a threshold Only units with value on both variables are used in the calculations \n  \n  \n    get_extremes \n    struktuR \n    Get extreme values Get extreme values in the sample dataset \n    r \n    Get extreme values Get extreme values in the sample dataset \n  \n  \n    Hb \n    Kostra \n    Detection of outliers using the Hidiroglou-Berthelot (HB) method \n    r \n    Detects possible outliers of a variable in period t by comparing it with revised values from period t-1 \n  \n  \n    LmImpute \n    Kostra \n    INTERNAL FUNCTION: Regeression imputation. \n    r \n    Imputation by weighted regeression, using lm, allowing multiple explanatory variables and multiple response variables. Impute missing and wrong values (category 3) by the model based on representative data (category 1). Some data are considered correct but not representative (category 2). \n  \n  \n    OutlierRegressionMicro \n    Kostra \n    Finding outliers of a sigle variable (y) by a regression model \n    r \n    outliers are found by using a limit for studentized residuals. \n  \n  \n    Quartile \n    Kostra \n    Detection of outliers using quartiles and by comparing with other \n    r \n    Detection of outliers using quartiles and by comparing with other data in same or previous period. \n  \n  \n    Rank2NumVar \n    Kostra \n    Comparing the biggest units with respect to two numerical \n    r \n    Calculating rank and share for two numerical variables, and the ratio between the variables Listing big units, either the k biggest units or units with value greater than a threshold \n  \n  \n    ThError \n    Kostra \n    Detection of 1000-error \n    r \n    Detects units with possible 1000-error by comparing values in period t with revised values from period t-1 \n  \n  \n    validator \n    validate \n    Define validation rules for data \n    r \n    Define validation rules for data"
  }
]